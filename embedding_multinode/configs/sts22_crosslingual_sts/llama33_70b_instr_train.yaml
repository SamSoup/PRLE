# embedding_multinode/configs/sts22_crosslingual_sts/llama33_70b_instr.yaml
backend: "ds_zero3"
ds_config_path: "configs/llama33_70b_instr_ds_zero3_inference.json"

data_module: "data.sts22_crosslingual_sts:STS22CrosslingualSTSDataModule"
data_kwargs:
  tokenize_inputs: true
  combine_fields: true
  combine_separator_token: "[SEP]"
  max_seq_length: 512
  train_batch_size: 64
  eval_batch_size: 64

# Informational
model: "meta-llama/Llama-3.3-70B-Instruct"

# Local snapshot dir (already downloaded)
model_local_dir: "/scratch/06782/ysu707/models/llama_33_70b_instr"

# ZeRO-3 inference config (no manifest/server)
ds_config_path: "embedding_multinode/ds_zero3_inference.json"

cache_dir: "/scratch/06782/ysu707/prle_cache/hf"

dtype: "bfloat16"
max_length: 1024
normalize: false
batch_size: 64
save_labels: false
splits: ["train"]
out_dir: "/scratch/06782/ysu707/PRLE/sts22_crosslingual/llama_33_70b_instr"
