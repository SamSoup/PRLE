{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef13021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/06782/ysu707/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & basic setup\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Reproducibility helpers\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e581053c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (3236, 8192) y_train: (3236,)\n",
      "X_val:   (1386, 8192) y_val:   (1386,)\n",
      "X_test:  (3958, 8192) y_test:  (3958,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: load embeddings from disk and labels from STS-B\n",
    "\n",
    "base_dir = \"/scratch/06782/ysu707/PRLE/sts22_crosslingual/llama_33_70b_instr\"\n",
    "\n",
    "X_train = np.load(os.path.join(base_dir, \"train_embeds.npy\"))\n",
    "X_val   = np.load(os.path.join(base_dir, \"validation_embeds.npy\"))\n",
    "X_test  = np.load(os.path.join(base_dir, \"test_embeds.npy\"))\n",
    "\n",
    "# Load STS-B dataset (sentence-transformers/stsb has train/validation/test splits)\n",
    "dataset = load_dataset(\"Samsoup/sts22-crosslingual-sts\")\n",
    "\n",
    "y_train = np.array(dataset[\"train\"][\"score\"], dtype=float)\n",
    "y_val   = np.array(dataset[\"validation\"][\"score\"], dtype=float)\n",
    "y_test  = np.array(dataset[\"test\"][\"score\"], dtype=float)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93fd2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full: (4622, 8192) y_train_full: (4622,)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: merge train and val for final training\n",
    "\n",
    "X_train_full = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train_full = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "print(\"X_train_full:\", X_train_full.shape, \"y_train_full:\", y_train_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd42ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: helpers for evaluation and pretty printing\n",
    "\n",
    "def eval_on_test(estimator, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Works for plain estimators or Pipeline(scaler -> regressor).\n",
    "    Returns mse, pearson_r, y_pred.\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r, _ = pearsonr(y_test, y_pred)\n",
    "    return mse, r, y_pred\n",
    "\n",
    "\n",
    "def make_predefined_split(X_train, X_val):\n",
    "    \"\"\"\n",
    "    Build X_all, y_all, predefined_split for GridSearchCV so that:\n",
    "    - fold=-1 rows are \"train portion\"\n",
    "    - fold=0 rows are \"validation portion\"\n",
    "    \"\"\"\n",
    "    X_all = np.concatenate([X_train, X_val], axis=0)\n",
    "    split_index = np.concatenate([\n",
    "        -1 * np.ones(len(X_train), dtype=int),\n",
    "         0 * np.ones(len(X_val),   dtype=int),\n",
    "    ])\n",
    "    predefined = PredefinedSplit(test_fold=split_index)\n",
    "    return X_all, predefined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78aa11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: generalized tuner using GridSearchCV with PredefinedSplit\n",
    "\n",
    "def tune_with_validation_cv(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    build_base_estimator_fn,\n",
    "    param_grid,\n",
    "    scale=False,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use sklearn's GridSearchCV with a manual train/val split.\n",
    "    - If scale=True: we build Pipeline([(\"scaler\", StandardScaler()), (\"regressor\", base_estimator)])\n",
    "      and param_grid keys must be 'regressor__<paramname>'.\n",
    "    - If scale=False: we pass the base estimator directly, and param_grid\n",
    "      keys are just the estimator's param names.\n",
    "    - We set cv=PredefinedSplit so it trains on train split only and scores on val split only.\n",
    "    - refit=True means: after finding best params, refit on ALL (train+val).\n",
    "    \"\"\"\n",
    "\n",
    "    # concat labels the same way we concat features\n",
    "    y_all = np.concatenate([y_train, y_val], axis=0)\n",
    "\n",
    "    # build predefined split\n",
    "    X_all, predefined_cv = make_predefined_split(X_train, X_val)\n",
    "\n",
    "    # base estimator for this model family\n",
    "    base_estimator = build_base_estimator_fn()\n",
    "\n",
    "    if scale:\n",
    "        estimator = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"regressor\", base_estimator),\n",
    "        ])\n",
    "        grid = param_grid  # expects regressor__... keys\n",
    "    else:\n",
    "        estimator = base_estimator\n",
    "        grid = param_grid  # expects direct param names\n",
    "\n",
    "    gscv = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=grid,\n",
    "        scoring=scoring,      # neg_mean_squared_error\n",
    "        cv=predefined_cv,     # train vs val as we defined\n",
    "        refit=True,           # after tuning, refit best on ALL (train+val)\n",
    "        n_jobs=-1,            # parallelize across param combos\n",
    "        verbose=verbose,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    gscv.fit(X_all, y_all)\n",
    "\n",
    "    # best_estimator_ is already refit on train+val\n",
    "    best_estimator = gscv.best_estimator_\n",
    "    best_params = gscv.best_params_\n",
    "\n",
    "    # gscv.best_score_ is neg-MSE on the validation fold, so flip sign\n",
    "    best_val_mse = -gscv.best_score_\n",
    "\n",
    "    print(\"===== GridSearch Summary =====\")\n",
    "    print(\"Best params:\", best_params)\n",
    "    print(\"Best validation MSE:\", best_val_mse)\n",
    "    print(\"==============================\")\n",
    "\n",
    "    return best_estimator, best_params, best_val_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7a2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: results container (we'll append rows per model)\n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13407f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear Regression ===\n",
      "Test MSE:       11.3496\n",
      "Test Pearson r: 0.0641\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Linear Regression (no hyperparams, no scaling)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_full, y_train_full)\n",
    "\n",
    "linreg_test_mse, linreg_test_r, _ = eval_on_test(linreg, X_test, y_test)\n",
    "\n",
    "print(\"=== Linear Regression ===\")\n",
    "print(f\"Test MSE:       {linreg_test_mse:.4f}\")\n",
    "print(f\"Test Pearson r: {linreg_test_r:.4f}\")\n",
    "print(\"=========================\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Linear Regression\",\n",
    "    \"Test MSE\": linreg_test_mse,\n",
    "    \"Pearson r\": linreg_test_r,\n",
    "    \"Chosen Hyperparams\": \"{}\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04701b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 24 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GridSearch Summary =====\n",
      "Best params: {'regressor__C': 1.0, 'regressor__epsilon': 0.2, 'regressor__gamma': 'auto', 'regressor__kernel': 'rbf'}\n",
      "Best validation MSE: 0.9851968121106149\n",
      "==============================\n",
      "=== SVR (RBF) ===\n",
      "Best params: {'regressor__C': 1.0, 'regressor__epsilon': 0.2, 'regressor__gamma': 'auto', 'regressor__kernel': 'rbf'}\n",
      "Best Val MSE:   0.9852\n",
      "Test MSE:       1.2793\n",
      "Test Pearson r: 0.3204\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: SVR (RBF kernel) with scaling\n",
    "\n",
    "def build_svr_base():\n",
    "    return SVR()\n",
    "\n",
    "svr_param_grid = {\n",
    "    \"regressor__kernel\": [\"rbf\"],\n",
    "    \"regressor__C\": [0.1, 1.0, 10.0, 100.0],\n",
    "    \"regressor__epsilon\": [0.05, 0.1, 0.2],\n",
    "    \"regressor__gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "svr_best_estimator, svr_best_params, svr_best_val_mse = tune_with_validation_cv(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    build_base_estimator_fn=build_svr_base,\n",
    "    param_grid=svr_param_grid,\n",
    "    scale=True,                          # SVR benefits from scaling\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "svr_test_mse, svr_test_r, _ = eval_on_test(svr_best_estimator, X_test, y_test)\n",
    "\n",
    "print(\"=== SVR (RBF) ===\")\n",
    "print(\"Best params:\", svr_best_params)\n",
    "print(f\"Best Val MSE:   {svr_best_val_mse:.4f}\")\n",
    "print(f\"Test MSE:       {svr_test_mse:.4f}\")\n",
    "print(f\"Test Pearson r: {svr_test_r:.4f}\")\n",
    "print(\"=================\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"SVR (RBF)\",\n",
    "    \"Test MSE\": svr_test_mse,\n",
    "    \"Pearson r\": svr_test_r,\n",
    "    \"Chosen Hyperparams\": str(svr_best_params),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4073407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 22 candidates, totalling 22 fits\n",
      "===== GridSearch Summary =====\n",
      "Best params: {'regressor__n_neighbors': 11, 'regressor__weights': 'distance'}\n",
      "Best validation MSE: 1.1257964258931654\n",
      "==============================\n",
      "=== KNN Regression ===\n",
      "Best params: {'regressor__n_neighbors': 11, 'regressor__weights': 'distance'}\n",
      "Best Val MSE:   1.1258\n",
      "Test MSE:       1.5803\n",
      "Test Pearson r: 0.1664\n",
      "======================\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: KNN Regression (also scale features)\n",
    "\n",
    "def build_knn_base():\n",
    "    return KNeighborsRegressor()\n",
    "\n",
    "knn_param_grid = {\n",
    "    \"regressor__n_neighbors\": [1, 3, 5, 7, 9, 11, 15, 21, 31, 41, 51],\n",
    "    \"regressor__weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "\n",
    "knn_best_estimator, knn_best_params, knn_best_val_mse = tune_with_validation_cv(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    build_base_estimator_fn=build_knn_base,\n",
    "    param_grid=knn_param_grid,\n",
    "    scale=True,                          # distance-based -> scale\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "knn_test_mse, knn_test_r, _ = eval_on_test(knn_best_estimator, X_test, y_test)\n",
    "\n",
    "print(\"=== KNN Regression ===\")\n",
    "print(\"Best params:\", knn_best_params)\n",
    "print(f\"Best Val MSE:   {knn_best_val_mse:.4f}\")\n",
    "print(f\"Test MSE:       {knn_test_mse:.4f}\")\n",
    "print(f\"Test Pearson r: {knn_test_r:.4f}\")\n",
    "print(\"======================\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"KNN Regression\",\n",
    "    \"Test MSE\": knn_test_mse,\n",
    "    \"Pearson r\": knn_test_r,\n",
    "    \"Chosen Hyperparams\": str(knn_best_params),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33953b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 40 candidates, totalling 40 fits\n",
      "===== GridSearch Summary =====\n",
      "Best params: {'max_depth': 3, 'min_samples_leaf': 20}\n",
      "Best validation MSE: 1.2774058102761354\n",
      "==============================\n",
      "=== Decision Tree ===\n",
      "Best params: {'max_depth': 3, 'min_samples_leaf': 20}\n",
      "Best Val MSE:   1.2774\n",
      "Test MSE:       1.4147\n",
      "Test Pearson r: 0.1192\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Decision Tree Regressor (no scaling)\n",
    "\n",
    "def build_dt_base():\n",
    "    return DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "\n",
    "dt_param_grid = {\n",
    "    \"max_depth\": [None, 3, 5, 7, 10, 15, 25, 40],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10, 20],\n",
    "}\n",
    "\n",
    "dt_best_estimator, dt_best_params, dt_best_val_mse = tune_with_validation_cv(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    build_base_estimator_fn=build_dt_base,\n",
    "    param_grid=dt_param_grid,\n",
    "    scale=False,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "dt_test_mse, dt_test_r, _ = eval_on_test(dt_best_estimator, X_test, y_test)\n",
    "\n",
    "print(\"=== Decision Tree ===\")\n",
    "print(\"Best params:\", dt_best_params)\n",
    "print(f\"Best Val MSE:   {dt_best_val_mse:.4f}\")\n",
    "print(f\"Test MSE:       {dt_test_mse:.4f}\")\n",
    "print(f\"Test Pearson r: {dt_test_r:.4f}\")\n",
    "print(\"=====================\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Decision Tree\",\n",
    "    \"Test MSE\": dt_test_mse,\n",
    "    \"Pearson r\": dt_test_r,\n",
    "    \"Chosen Hyperparams\": str(dt_best_params),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b4948c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 54 candidates, totalling 54 fits\n",
      "===== GridSearch Summary =====\n",
      "Best params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\n",
      "Best validation MSE: 1.0749238572874051\n",
      "==============================\n",
      "=== Random Forest ===\n",
      "Best params: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}\n",
      "Best Val MSE:   1.0749\n",
      "Test MSE:       1.3016\n",
      "Test Pearson r: 0.3032\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Random Forest Regressor (no scaling)\n",
    "\n",
    "def build_rf_base():\n",
    "    return RandomForestRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "rf_best_estimator, rf_best_params, rf_best_val_mse = tune_with_validation_cv(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    build_base_estimator_fn=build_rf_base,\n",
    "    param_grid=rf_param_grid,\n",
    "    scale=False,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "rf_test_mse, rf_test_r, _ = eval_on_test(rf_best_estimator, X_test, y_test)\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(\"Best params:\", rf_best_params)\n",
    "print(f\"Best Val MSE:   {rf_best_val_mse:.4f}\")\n",
    "print(f\"Test MSE:       {rf_test_mse:.4f}\")\n",
    "print(f\"Test Pearson r: {rf_test_r:.4f}\")\n",
    "print(\"====================\")\n",
    "\n",
    "results.append({\n",
    "    \"Model\": \"Random Forest\",\n",
    "    \"Test MSE\": rf_test_mse,\n",
    "    \"Pearson r\": rf_test_r,\n",
    "    \"Chosen Hyperparams\": str(rf_best_params),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c0a8f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Summary Table (sorted by Pearson r desc, then MSE asc) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Pearson r</th>\n",
       "      <th>Chosen Hyperparams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVR (RBF)</td>\n",
       "      <td>1.2793</td>\n",
       "      <td>0.3204</td>\n",
       "      <td>{'regressor__C': 1.0, 'regressor__epsilon': 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.3016</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'sqrt', 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>1.5803</td>\n",
       "      <td>0.1664</td>\n",
       "      <td>{'regressor__n_neighbors': 11, 'regressor__wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.4147</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>11.3496</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Test MSE  Pearson r  \\\n",
       "0          SVR (RBF)    1.2793     0.3204   \n",
       "1      Random Forest    1.3016     0.3032   \n",
       "2     KNN Regression    1.5803     0.1664   \n",
       "3      Decision Tree    1.4147     0.1192   \n",
       "4  Linear Regression   11.3496     0.0641   \n",
       "\n",
       "                                  Chosen Hyperparams  \n",
       "0  {'regressor__C': 1.0, 'regressor__epsilon': 0....  \n",
       "1  {'max_depth': 20, 'max_features': 'sqrt', 'min...  \n",
       "2  {'regressor__n_neighbors': 11, 'regressor__wei...  \n",
       "3           {'max_depth': 3, 'min_samples_leaf': 20}  \n",
       "4                                                 {}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model             |   Test MSE |   Pearson r | Chosen Hyperparams                                                                                       |\n",
      "|-------------------|------------|-------------|----------------------------------------------------------------------------------------------------------|\n",
      "| SVR (RBF)         |     1.2793 |      0.3204 | {'regressor__C': 1.0, 'regressor__epsilon': 0.2, 'regressor__gamma': 'auto', 'regressor__kernel': 'rbf'} |\n",
      "| Random Forest     |     1.3016 |      0.3032 | {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'n_estimators': 500}                    |\n",
      "| KNN Regression    |     1.5803 |      0.1664 | {'regressor__n_neighbors': 11, 'regressor__weights': 'distance'}                                         |\n",
      "| Decision Tree     |     1.4147 |      0.1192 | {'max_depth': 3, 'min_samples_leaf': 20}                                                                 |\n",
      "| Linear Regression |    11.3496 |      0.0641 | {}                                                                                                       |\n",
      "Saved sts22_crosslingual_regression_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Final pretty results table\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# reorder / round / sort\n",
    "df_results = df_results[[\"Model\", \"Test MSE\", \"Pearson r\", \"Chosen Hyperparams\"]]\n",
    "df_results[\"Test MSE\"]   = df_results[\"Test MSE\"].astype(float).round(4)\n",
    "df_results[\"Pearson r\"]  = df_results[\"Pearson r\"].astype(float).round(4)\n",
    "\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"Pearson r\", \"Test MSE\"],\n",
    "    ascending=[False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"=== Summary Table (sorted by Pearson r desc, then MSE asc) ===\")\n",
    "display(df_results)  # in notebook this shows a nice HTML table\n",
    "\n",
    "from tabulate import tabulate\n",
    "print(tabulate(df_results, headers=\"keys\", tablefmt=\"github\", showindex=False))\n",
    "\n",
    "# optional archive\n",
    "dir = \"/work/06782/ysu707/ls6/PRLE/results/sts22_crosslingual/llama_33_70b_instr/wrapperbox\"\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "df_results.to_csv(f\"{dir}/results.csv\", index=False)\n",
    "print(\"Saved sts22_crosslingual_regression_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRLE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
